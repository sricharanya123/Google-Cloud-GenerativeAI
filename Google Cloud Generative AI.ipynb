{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b03RPIOMHYj",
        "outputId": "9e66d306-af1c-497c-9c26-d7cee4aa2ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.9-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.90)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.9-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.9 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# Load pretrained YOLO model\n",
        "model = YOLO(\"yolov5s.pt\")\n",
        "\n",
        "# Read image\n",
        "image = cv2.imread(\"construction_site.jpg\")\n",
        "\n",
        "# Run detection\n",
        "results = model(image)\n",
        "\n",
        "# Display detected objects\n",
        "for r in results:\n",
        "    for box in r.boxes:\n",
        "        cls = int(box.cls[0])\n",
        "        label = model.names[cls]\n",
        "        print(\"Detected Material:\", label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L180jC6SMUOb",
        "outputId": "cee00207-48eb-4da1-8f4e-1bc3574b1f39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov5su.pt to 'yolov5su.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17.7MB 127.7MB/s 0.1s\n",
            "WARNING ‚ö†Ô∏è 'source' is missing. Using 'source=/usr/local/lib/python3.12/dist-packages/ultralytics/assets'.\n",
            "\n",
            "image 1/2 /usr/local/lib/python3.12/dist-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 869.2ms\n",
            "image 2/2 /usr/local/lib/python3.12/dist-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 2 ties, 551.4ms\n",
            "Speed: 11.6ms preprocess, 710.3ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Detected Material: person\n",
            "Detected Material: bus\n",
            "Detected Material: person\n",
            "Detected Material: person\n",
            "Detected Material: person\n",
            "Detected Material: person\n",
            "Detected Material: person\n",
            "Detected Material: tie\n",
            "Detected Material: tie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load pretrained model\n",
        "model = resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create a dummy image if it doesn't exist\n",
        "# This is to ensure the code runs even if 'concrete_sample.jpg' is not provided\n",
        "try:\n",
        "    img = Image.open(\"concrete_sample.jpg\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Creating a dummy 'concrete_sample.jpg' as it was not found.\")\n",
        "    dummy_image_data = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)\n",
        "    img = Image.fromarray(dummy_image_data)\n",
        "    img.save(\"concrete_sample.jpg\")\n",
        "\n",
        "# Load image (or use the newly created dummy image)\n",
        "img = Image.open(\"concrete_sample.jpg\")\n",
        "img = transform(img).unsqueeze(0)\n",
        "\n",
        "# Prediction\n",
        "with torch.no_grad():\n",
        "    output = model(img)\n",
        "\n",
        "predicted_class = torch.argmax(output, 1)\n",
        "print(\"Material Class ID:\", predicted_class.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsdwF64nMg7f",
        "outputId": "cdfa85a1-7c03-449a-de82-84bb7a0dd0d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a dummy 'concrete_sample.jpg' as it was not found.\n",
            "Material Class ID: 610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "feature_extractor = resnet50(pretrained=True)\n",
        "feature_extractor.fc = nn.Identity()\n",
        "feature_extractor.eval()\n",
        "\n",
        "features = feature_extractor(img)\n",
        "print(\"Extracted Feature Vector Shape:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y8fOcNMN0wX",
        "outputId": "b3765837-e1c2-4b63-9af1-da7c14cae437"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Feature Vector Shape: torch.Size([1, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImageCaptioningModel(nn.Module):\n",
        "    def __init__(self, feature_size, hidden_size, vocab_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(feature_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, features):\n",
        "        features = features.unsqueeze(1)\n",
        "        outputs, _ = self.lstm(features)\n",
        "        captions = self.fc(outputs)\n",
        "        return captions\n"
      ],
      "metadata": {
        "id": "8c8ZIszCN7qi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example vocabulary\n",
        "vocab = {\n",
        "    0: \"Concrete structure\",\n",
        "    1: \"Steel reinforcement\",\n",
        "    2: \"Brick masonry\",\n",
        "    3: \"Multi-storey building under construction\"\n",
        "}\n",
        "\n",
        "predicted_index = 3\n",
        "print(\"Generated Description:\", vocab[predicted_index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcF3fHrXOA9V",
        "outputId": "e01b870e-30ac-4c5a-a0f8-cf56effe6a76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Description: Multi-storey building under construction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(materials, stage):\n",
        "    report = f\"\"\"\n",
        "    Project Progress Report:\n",
        "    ------------------------\n",
        "    Current Stage: {stage}\n",
        "\n",
        "    Identified Materials:\n",
        "    \"\"\"\n",
        "    for m in materials:\n",
        "        report += f\"- {m}\\n\"\n",
        "\n",
        "    report += \"\"\"\n",
        "    Construction Method:\n",
        "    Reinforced concrete framed structure.\n",
        "\n",
        "    Next Phase:\n",
        "    Slab casting and vertical expansion.\n",
        "    \"\"\"\n",
        "    return report\n"
      ],
      "metadata": {
        "id": "g-5d0OE_OGhe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "materials = [\"Concrete\", \"Steel\", \"Bricks\"]\n",
        "stage = \"Foundation and Column Completion\"\n",
        "\n",
        "print(generate_report(materials, stage))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ9Hwb4xOK0W",
        "outputId": "81b2bfbd-d5d8-438f-bd44-9412974f73d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Project Progress Report:\n",
            "    ------------------------\n",
            "    Current Stage: Foundation and Column Completion\n",
            "\n",
            "    Identified Materials:\n",
            "    - Concrete\n",
            "- Steel\n",
            "- Bricks\n",
            "\n",
            "    Construction Method:\n",
            "    Reinforced concrete framed structure.\n",
            "\n",
            "    Next Phase:\n",
            "    Slab casting and vertical expansion.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Ejm0i5aOPbg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}